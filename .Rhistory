WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + FirePlaces
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + FirePlaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
y = train_train$SalePrice
y.test = train_test$SalePrice
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
grid = 10^seq(1, -5, length = 100)
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
lasso_model = glmnet(x, y, alpha = 1, lambda = grid)
plot(lasso_model, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Running 5-fold cross validation.
set.seed(0)
cv.lasso = cv.glmnet(x, y,
lambda = grid, alpha = 1, nfolds = 10)
cv.lasso = cv.glmnet(x, y,
lambda = grid, alpha = 1, nfolds = 10)
x
y
dim(x)
dim(y)
str(y)
nrow(y)
#Creating training and testing sets with 70-30 split
set.seed(0)
train_train_idx = sample(1:nrow(train), 7*nrow(train)/10)
train_train = train[train_train_idx,]
train_test  = train[-train_train_idx,]
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
y = train_train$SalePrice
y.test = train_test$SalePrice
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
grid = 10^seq(1, -5, length = 100)
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
library(dplyr)
library(car)
library(psych)
train = read.csv('./data/train_superclean.csv')
test = read.csv('./data/test_superclean.csv')
library(ISLR)
library(glmnet)
#Creating training and testing sets with 70-30 split
set.seed(0)
train_train_idx = sample(1:nrow(train), 7*nrow(train)/10)
train_train = train[train_train_idx,]
train_test  = train[-train_train_idx,]
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
y = train_train$SalePrice
y.test = train_test$SalePrice
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
grid = 10^seq(1, -5, length = 100)
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge, main = "Ridge Regression\n")
best.lambda.ridge = cv.ridge$lambda.min
best.lambda.ridge # 0.01
#What is the test MSE associated with this best value of lambda?
ridge.models.train = glmnet(x, y, alpha = 0, lambda = grid)
ridge.best.lambda.train = predict(ridge.models.train, s = best.lambda.ridge, newx = x.test)
sqrt(mean((ridge.best.lambda.train - y.test)^2)) #0.04010766
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge, main = "Ridge Regression\n")
best.lambda.ridge = cv.ridge$lambda.min
#What is the test MSE associated with this best value of lambda?
ridge.models.train = glmnet(x, y, alpha = 0, lambda = grid)
ridge.best.lambda.train = predict(ridge.models.train, s = best.lambda.ridge, newx = x.test)
lasso_model = glmnet(x, y, alpha = 1, lambda = grid)
plot(lasso_model, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Running 5-fold cross validation.
set.seed(0)
cv.lasso = cv.glmnet(x, y,
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso, main = "Lasso Regression\n")
best.lambda.lasso = cv.lasso$lambda.min
best.lambda.lasso #0.01
lasso.model.train = glmnet(x, y, alpha = 1, lambda = 10)
mean(abs(y.test-predict(lasso.model.train,newx = x.test)))
y.predict=predict(lasso.model.train, newx = x.test)
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
y.predict=predict(lasso.model.train, newx = x.test)
lasso.model.train = glmnet(x, y, alpha = 1, lambda = 10)
mean(abs(y.test-predict(lasso.model.train,newx = x.test)))
predict(lasso.model.train,newx = a.test)
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
lasso_model = glmnet(x, y, alpha = 1, lambda = grid)
plot(lasso_model, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Running 5-fold cross validation.
set.seed(0)
cv.lasso = cv.glmnet(x, y,
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso, main = "Lasso Regression\n")
best.lambda.lasso = cv.lasso$lambda.min
best.lambda.lasso #0.01
lasso.model.train = glmnet(x, y, alpha = 1, lambda = 10)
mean(abs(y.test-predict(lasso.model.train,newx = x.test)))
y.predict=predict(lasso.model.train, newx = x.test)
y.test
y.predict
class(.Last.value)
y.predict = as.data.frame(y.predict)
class(y.predict)
test['Id']
a = cbind(y.predict, test["id"])
a = cbind(y.predict, test["id"])
a = cbind(y.predict, test[,"id"])
a = cbind(y.predict, test[,"Id"])
test
str(test)
dim(test)
View(test)
test["Id"]
test["Id", na.omit = FALSE]
library(dplyr)
sqrt(0.03932375)
test_y = test %>% mutate(SalePrice-hat = y.predict)
test_y = test %>% mutate(,SalePrice-hat = y.predict)
test_y = test %>% mutate(SalePrice.hat = y.predict)
test_id_y = test %>% select("Id", 'SalePrice.hat')
test_id_y = test_y %>% select("Id", 'SalePrice.hat')
View(test_id_y)
View(test_id_y)
test_id_y
View(test_y)
View(test)
View(test_y)
test_y = test %>% mutate(SalePrice.hat = y.predict, na.encode = FALSE)
test_id_y = test_y %>% select("Id", 'SalePrice.hat', na.encode = FALSE)
View(test_y)
test_id_y = test_y %>% select("Id", 'SalePrice.hat', na.encode = FALSE)
test_y = test %>% mutate(SalePrice.hat = y.predict, na.encode = TRUE)
View(test_y)
test["id"]
test["Id"]
View(test_id_y)
View(test_id_y)
View(test_id_y)
View(x)
View(train_test)
View(test_y)
View(test_id_y)
View(y.predict)
class(y.predict)
library(dplyr)
library(car)
library(psych)
train = read.csv('./data/train_superclean.csv')
test = read.csv('./data/test_superclean.csv')
View(test_id_y)
View(test_id_y$Id)
View(test_id_y$SalePrice.hat)
y.predict=predict(lasso.model.train, newx = x.test)
#Creating training and testing sets with 70-30 split
set.seed(0)
train_train_idx = sample(1:nrow(train), 7*nrow(train)/10)
train_train = train[train_train_idx,]
train_test  = train[-train_train_idx,]
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
y = train_train$SalePrice
y.test = train_test$SalePrice
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
grid = 10^seq(1, -5, length = 100)
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge, main = "Ridge Regression\n")
best.lambda.ridge = cv.ridge$lambda.min
library(ISLR)
library(glmnet)
#Creating training and testing sets with 70-30 split
set.seed(0)
train_train_idx = sample(1:nrow(train), 7*nrow(train)/10)
train_train = train[train_train_idx,]
train_test  = train[-train_train_idx,]
x = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_train)
y = train_train$SalePrice
y.test = train_test$SalePrice
x.test = model.matrix(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train_test)
grid = 10^seq(1, -5, length = 100)
#Running 5-fold cross validation.
set.seed(0)
cv.ridge = cv.glmnet(x, y, lambda = grid, alpha = 0, nfolds = 10)
plot(cv.ridge, main = "Ridge Regression\n")
best.lambda.ridge = cv.ridge$lambda.min
best.lambda.ridge # 0.01
#What is the test MSE associated with this best value of lambda?
ridge.models.train = glmnet(x, y, alpha = 0, lambda = grid)
ridge.best.lambda.train = predict(ridge.models.train, s = best.lambda.ridge, newx = x.test)
sqrt(mean((ridge.best.lambda.train - y.test)^2)) #0.04010766
mean(abs(ridge.best.lambda.train - y.test)) #0.0968727 , absolute error
#or
ridge.best.lambda.train = predict.cv.glmnet(cv.ridge, s ="lambda.min", newx = x.test)
mean((ridge.best.lambda.train - y.test)^2) #0.04010766
lasso_model = glmnet(x, y, alpha = 1, lambda = grid)
plot(lasso_model, xvar = "lambda", label = TRUE, main = "Lasso Regression")
#Running 5-fold cross validation.
set.seed(0)
cv.lasso = cv.glmnet(x, y,
lambda = grid, alpha = 1, nfolds = 10)
plot(cv.lasso, main = "Lasso Regression\n")
best.lambda.lasso = cv.lasso$lambda.min
best.lambda.lasso #0.01
lasso.model.train = glmnet(x, y, alpha = 1, lambda = 10)
mean(abs(y.test-predict(lasso.model.train,newx = x.test)))
y.predict=predict(lasso.model.train, newx = x.test)
y.predict
test[1:438,]
y.test
y.predict.index()
index(y.predict)
View(y.predict)
y.predict[0]
y_merge = merge(x = y.predict, y = test, by = "Id", all = TRUE)
colnames(y.predict)
colnames(y.predict)=c('index','s0')
y.predict.df$index=rownames(y.predict)
y.predict$index=rownames(y.predict)
View(y.predict)
y.predict=predict(lasso.model.train, newx = x.test)
y.predict
y.predictt = y.predict
View(y.predictt)
merge(x = y.predictt , y = test , by = "row.names")
b = merge(x = y.predictt , y = test , by = "row.names")
View(b)
b = merge(x = y.predictt , y = test , by.x = "row.names",by.y="Id")
View(b)
class("Id")
b = merge(x = y.predictt , y = test , by.x = "row.names",as.numeric(by.y="Id"))
b = merge(x = y.predictt , y = test , by.x = "row.names",by.y=as.numeric("Id"))
test$Id = as.numeric(test$Id)
class('Id')
class(test$Id)
b = merge(x = y.predictt , y = test , by.x = "row.names",by.y="Id")
View(test)
b = merge(x = y.predictt , y = test , by = "row.names")
View(b)
names(b$s0) = names(b$SalePrice)
View(b)
names(b) <- names("SalePrice", "s0", names(b))
names(b)[names(b)=="s0"] <- "SalePrice"
View(b)
a = b[2,3 :]
b[2]
b[2,3]
a  = select(b, SalePrice, Id)
View(a)
write.csv(a, file = "kaggle_test.csv",row.names=FALSE)
read.csv = "kaggle_test.csv"
c = read.csv = "kaggle_test.csv"
c = read.csv("kaggle_test.csv")
View(c)
write.csv(a, file = "kaggle_test.csv",row.names=FALSE)
a = select(a, "Id", "SalePrice")
View(a)
write.csv(a, file = "kaggle_test.csv",row.names=FALSE)
c  = read.csv("kaggle_test.csv")
View(c)
# best model
model.n5 = lm(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
summary(model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
plot(model.n5)
nfrow(2,2)
plot(model.n5)
influencePlot(model.n5)
par(mfrow=c(2,3))
plot(model.n5)
influencePlot(model.n5)
influencePlot(model.n5)
library(MASS)
model.nn5 = rlm(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
summary(model.nn5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
vif(model.nn5) #
plot(model.nn5)
influencePlot(model.nn5)
# best model
model.n5 = lm(log(SalePrice) ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
KitchenAbvGr + GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
summary(model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
vif(model.n5) #
plot(model.n5)
anova(model.n5)
# best model
model.n5 = lm(log(SalePrice) ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
summary(model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
vif(model.n5) #
plot(model.n5)
install.packages('influence.ME')
library(lme4)
infl <- influence(model.n5, obs = TRUE)
library(influence.ME)
infl <- influence(model.n5, obs = TRUE)
library(lme4)
model <- model.n5
library(influence.ME)
infl <- influence(model, obs = TRUE)
library(lme4)
model <- lmer(log(SalePrice) ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
# best model
model.n5 = lm(log(SalePrice) ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
summary(model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
vif(model.n5) #
AIC(model.n5) # 33941.43
par(mfrow=c(2,3))
plot(model.n5)
influencePlot(model.n5)
plot_summs(model.n5)
library(ggiraphExtra)
plot_summs(model.n5)
library(jtools)
library(jtools)
plot_summs(model.n5)
plot_summs(model.n5, scale = TRUE, plot.distributions = TRUE)
effect_plot(model.n5, pred = OverallQual , interval = TRUE, plot.points = TRUE)
effect_plot(model.n5, pred = Utilities , interval = TRUE, plot.points = TRUE)
effect_plot(model.n5, pred = X2ndFlrSF  , interval = TRUE, plot.points = TRUE)
sub.model.n5 = lm(log.SalePrice ~ YearBuilt +  LotArea + MiscVal + YearRemodAdd  +
MasVnrArea + GarageArea + TotalBsmtSF + BsmtFinSF1 + GrLivArea +
ScreenPorch +  WoodDeckSF +
+ X2ndFlrSF, data = train)
sub.model.n5 = lm(log(SalePrice) ~ YearBuilt +  LotArea + MiscVal + YearRemodAdd  +
MasVnrArea + GarageArea + TotalBsmtSF + BsmtFinSF1 + GrLivArea +
ScreenPorch +  WoodDeckSF +
+ X2ndFlrSF, data = train)
summary(sub.model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
plot_summs(model.n5, scale = TRUE, plot.distributions = TRUE)
plot_summs(rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
plot_summs(rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
# best model
model.n5 = lm(log(SalePrice) ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
plot_summs(rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
train = read.csv('./data/train_superclean.csv')
# best model
model.n5 = lm(log(SalePrice) ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
plot_summs(rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
# best model
model.n5 = lm(SalePrice ~ OverallQual +  LotArea + LotFrontage + OverallCond +
MasVnrArea + BsmtFinSF1 + BsmtFullBath + X2ndFlrSF + Fireplaces +
GarageCars + Condition2 + HeatingQC +
WoodDeckSF + ScreenPorch + PoolArea + X1stFlrSF + KitchenQual + Condition1 +
Utilities +  MSZoning  + SaleCondition + Functional +
BsmtExposure + RoofMatl + YearRemodAdd +
CentralAir, data = train)
plot_summs(rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
plot_summs(sub.model.n5, rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
plot_summs(sub.model.n5, rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
sub.model.n5 = lm(SalePrice ~ YearBuilt +  LotArea + MiscVal + YearRemodAdd  +
MasVnrArea + GarageArea + TotalBsmtSF + BsmtFinSF1 + GrLivArea +
ScreenPorch +  WoodDeckSF +
+ X2ndFlrSF, data = train)
plot_summs(sub.model.n5, rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
plot_summs(model.n5, sub.model.n5, rescale.distributions = TRUE ,  scale = TRUE, plot.distributions = TRUE)
plot_summs(model.n5, sub.model.n5, rescale.distributions = TRUE ,  scale = TRUE)
plot_summs(model.n5, sub.model.n5, scale = TRUE)
plot_summs(sub.model.n5, rescale.distributions = TRUE , model.n5, scale = TRUE, plot.distributions = TRUE)
plot_summs(model.n5, rescale.distributions = TRUE ,  scale = TRUE, plot.distributions = TRUE)
plot_summs(color.class = green, model.n5, rescale.distributions = TRUE ,  scale = TRUE, plot.distributions = TRUE)
plot_summs(color.class = 0d98ba, model.n5, rescale.distributions = TRUE ,  scale = TRUE, plot.distributions = TRUE)
sub.model.n5 = lm(log(SalePrice) ~ YearBuilt +  LotArea + MiscVal + YearRemodAdd  +
MasVnrArea + GarageArea + TotalBsmtSF + BsmtFinSF1 + GrLivArea +
ScreenPorch +  WoodDeckSF +
+ X2ndFlrSF, data = train)
summary(sub.model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
sub.model.n5 = lm(log(SalePrice) ~ YearBuilt +  LotArea + MiscVal + YearRemodAdd  +
MasVnrArea + GarageArea + TotalBsmtSF + BsmtFinSF1 + GrLivArea +
ScreenPorch +  WoodDeckSF +
+ X2ndFlrSF, data = train)
summary(sub.model.n5) #Adjusted R-squared:  0.91  , F-statistic: 135.1
vif(sub.model.n5)
